{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/julianganzabal/.kaggle/competitions/fashion-mnist-itba-lab-ml/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(folder+'train_images.npy')\n",
    "y = np.loadtxt(folder+'train_labels.csv', delimiter=',', skiprows=1)\n",
    "x_test_ = np.load(folder+'test_images.npy')\n",
    "y_test = np.loadtxt('test_labels.csv', delimiter=',', skiprows=1)\n",
    "x_train__, x_valid__, y_train, y_valid = train_test_split(x, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train__.reshape(x_train__.shape + (1,))\n",
    "x_valid_ = x_valid__.reshape(x_valid__.shape + (1,))\n",
    "x_test = x_test_.reshape(x_test_.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros((x_train_.shape[0], x_train_.shape[1], x_train_.shape[2], 3))\n",
    "x_valid = np.zeros((x_valid_.shape[0], x_valid_.shape[1], x_valid_.shape[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:,:,:,0] = x_train_[:,:,:,0]\n",
    "x_train[:,:,:,1] = x_train_[:,:,:,0]\n",
    "x_train[:,:,:,2] = x_train_[:,:,:,0]\n",
    "\n",
    "x_valid[:,:,:,0] = x_valid_[:,:,:,0]\n",
    "x_valid[:,:,:,1] = x_valid_[:,:,:,0]\n",
    "x_valid[:,:,:,2] = x_valid_[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 3)\n",
      "(6000, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEqZJREFUeJzt3V1sVdeVB/D/CjgEjBMwxsZgO+kQ\nkhAhBYJBkxANiSapUoRE+lACDxUjVaUPVJpGTTSIl+alUjRKS/MwqkInqCC1oQ0tEx6iiAiNEipF\nERiFksQJkMTDlzFfDdh8OdhrHnyoXOKz1uWee++59vr/JGT7Lm/f7Wv/ubbX2XuLqoKI4rkt7wkQ\nUT4YfqKgGH6ioBh+oqAYfqKgGH6ioBh+oqAYfqKgGH6ioMZX8s5EZExeTrhw4UKz3tHRkenjT58+\n3az39/en1gYGBsyxWa/wFBGzPn58+rdYU1OTOfazzz4rak7Rqar9RUlIli++iDwN4BUA4wD8t6q+\n5Lz/mAz/4OCgWb/ttmw/YK1bt86sHz16NLXW29trjrX+4yjEuHHjzPq0adNSay+88II5dsmSJUXN\nKbpCw1/0d6WIjAPwXwC+A+BBAKtF5MFiPx4RVVaWp6TFAI6o6heq2g9gG4AVpZkWEZVblvDPAnBs\n2NvHk9v+gYisFZF9IrIvw30RUYll+YPfSL9XfON3elXdBGATMHZ/5ycajbI88x8H0Drs7RYAJ7NN\nh4gqJUv49wKYIyLfEpHbAawCsLM00yKicsva6lsG4FcYavVtVtWfO+/PH/tH8OSTT5r13bt3m/W6\nurrUmteHr6+vN+uXLl0y6973z5UrV4r+2Hv27DHrjz32mFmPqtBWX6aLfFT1LQBvZfkYRJQPXt5L\nFBTDTxQUw08UFMNPFBTDTxQUw08UVKY+/y3f2Rjt8/f19Zn1Rx55xKz39PSY9cbGRrN+4cKF1Nqk\nSZPMsdeuXTPrkydPNuvd3d1m3VryO2HCBHOsdY0AACxbtsysb9261ayPVWVf0ktEoxvDTxQUw08U\nFMNPFBTDTxQUw08UFFt9Bbp48WJqzdqhFgDmzZtn1m+//Xaz7u3++9VXX6XWvFZeliW5gL8s15p7\nS0uLOdarnzhxwqxby5kPHjxojh3N2OojIhPDTxQUw08UFMNPFBTDTxQUw08UFMNPFBT7/AVqa2tL\nrc2cOdMcW1tba9a9JcHeMdt33XVXas3rw3v1M2fOmHXvGoepU6em1r7++mtz7B133GHWPdevX0+t\nedcI7Ntnny7X0NBg1r1ceVuqZ8E+PxGZGH6ioBh+oqAYfqKgGH6ioBh+oqAYfqKgMp3SKyJdAHoB\nDAC4rqrtpZhUMQYHB826tyb++eefN+s7duxIrXl9fK+n6/Wz+/v7zbrVz+7t7TXHXr582ax7c/eu\nUbC2Dvf2MfC+ph5r23Hv+oQ33ngj032PBpnCn3hCVc+W4OMQUQXxx36ioLKGXwHsEpEOEVlbigkR\nUWVk/bF/iaqeFJFGAO+IyKeq+t7wd0j+U+B/DERVJtMzv6qeTF6eBrADwOIR3meTqrbn+cdAIvqm\nosMvIrUiUnfjdQDfBvBRqSZGROWV5cf+JgA7klbQeAC/V9W3SzIrIiq7osOvql8AeKiEc8kk6/ro\n1tZWs15XV5da89bbe732+vp6s+59btbe/BMnTjTHWp8XAFy9etWsW2cGAMC5c+dSazNmzDDHemcO\neNcJjB+f/u3tXffR2dlp1j3lXK9fKmz1EQXF8BMFxfATBcXwEwXF8BMFxfATBcWtuxOLFi0y61Y7\nr7Gx0Rx78uRJsz5u3Diz7rXrrGW51rLWQu7ba/V5y5G9VqDFWyrtbf09ZcqU1Jq3lPnAgQNm3VvK\nnCdu3U1EJoafKCiGnygohp8oKIafKCiGnygohp8oqFLs3jsqeEdNe7369vb0jYisrbMBf8mud0z2\nhQsXzLrVa/e2v/bu2+u1d3d3m3XriG7vGgBrLOAfg+0tCbZYx54DwP79+836fffdV/R9Vwqf+YmC\nYviJgmL4iYJi+ImCYviJgmL4iYJi+ImCCtPn37p1q1lvaWkx61a/POs1BN6aeo91nYG3hbS3/bV3\nHUCW9fzeevwvv/zSrE+fPt2sW5+7tx7fW+//6quvmvXRgM/8REEx/ERBMfxEQTH8REEx/ERBMfxE\nQTH8REG5+/aLyGYAywGcVtV5yW31AP4A4B4AXQBWqurf3DvLcd/+rOurrfXdp06dMsfOnj3brB86\ndMise8dJNzU1pda8frV3JoB3nUB/f79Zt65B8PY58M478Hr1CxcuTK15XzNvr4Hm5maz/v7775v1\ncirlvv2/BfD0TbetB7BbVecA2J28TUSjiBt+VX0PwPmbbl4BYEvy+hYAz5R4XkRUZsX+zt+kqt0A\nkLy0r18loqpT9mv7RWQtgLXlvh8iujXFPvP3iEgzACQvT6e9o6puUtV2VU3fAZOIKq7Y8O8EsCZ5\nfQ2AN0szHSKqFDf8IvI6gPcB3C8ix0XkBwBeAvCUiBwG8FTyNhGNIm6fv6R3lmOf31szP3fuXLNu\nnXPf1dWV6b4nTJiQqW714r0+vbem/s477zTrXq/d2gfB+9je9Q0dHR1mvaGhIbV29913m2PPnTtn\n1nt6esy697iUUyn7/EQ0BjH8REEx/ERBMfxEQTH8REEx/ERBjZmtuw8fPmzWvSW93hbWVkusrq7O\nHHvs2DGz3tbWZtY9NTU1RY/1jhf3lux6rUSrley1w6ZMmWLWvWO0rRard3S51171tjT3jvB++OGH\nzXol8JmfKCiGnygohp8oKIafKCiGnygohp8oKIafKKgx0+ffu3evWff60Vn61d41At6SXq/X7o2/\nevVqam3SpEnm2Kxbc3v9cusI74GBAXOst9zc+9ys8d7W3N41Bt7jtmvXLrNeDfjMTxQUw08UFMNP\nFBTDTxQUw08UFMNPFBTDTxTUmOnzf/LJJ2a9trbWrHtHWY8fn/5Qef3qrGvmrV45YPecvT6810v3\nPjev322N9+7be1y8urUm33tcrGsnAGDatGlm/e233zbr1YDP/ERBMfxEQTH8REEx/ERBMfxEQTH8\nREEx/ERBuX1+EdkMYDmA06o6L7ntRQA/BHAmebcNqvpWuSZZiGvXrpl1b0281cf3eP1mr5+dtRdv\nHWXt9auzXEMA+Ed8W31+72vm7Z3vHeFtXV/hfb2z7utvHQ9eLQp55v8tgKdHuH2jqs5P/uUafCK6\ndW74VfU9AOcrMBciqqAsv/P/WET+KiKbRWRqyWZERBVRbPh/DWA2gPkAugH8Iu0dRWStiOwTkX1F\n3hcRlUFR4VfVHlUdUNVBAL8BsNh4302q2q6q7cVOkohKr6jwi0jzsDe/C+Cj0kyHiCqlkFbf6wAe\nB9AgIscB/AzA4yIyH4AC6ALwozLOkYjKwA2/qq4e4ebXyjCXTHp6ejKNz9IP98Y2Njaa9fr6erPu\nnQVvzc3bS8Dj9bu9Xr11poF3DYF3bcbMmTPN+pkzZ1Jr3uPinQnQ2dlp1pcsWWLWt2/fbtYrgVf4\nEQXF8BMFxfATBcXwEwXF8BMFxfATBTVmtu4+fvy4WfeWrnotLast5S1rnTVrlln3xntLeq3lpd5y\nY29rbq/l5bXMrGW33txqamrMunc0+tmzZ1NrXpvxypUrZt2zfPlys/7cc89l+vilwGd+oqAYfqKg\nGH6ioBh+oqAYfqKgGH6ioBh+oqDGTJ/f65V7da/nbPWUvWWt3hbTra2tZv3jjz8269Z1AF4fPusW\n1t7jZl0n4F1j4PX5vSW/1ty9sX19fWbdM2fOnEzjK4HP/ERBMfxEQTH8REEx/ERBMfxEQTH8REEx\n/ERBjZk+/6JFi8x6R0eHWfe2z758+XJqzeuVe/3sw4cPm3Wv125dw1DuPr63Lt4aX1tba449cuSI\nWfe2RJ8yZUpqzZv3xYsXzbr3uHrXlVQDPvMTBcXwEwXF8BMFxfATBcXwEwXF8BMFxfATBeX2+UWk\nFcBWADMADALYpKqviEg9gD8AuAdAF4CVqvq38k3VtnTpUrO+ceNGsz5x4kSz3tvbm1qbPHmyOdbb\nd987U8Dbn976+N66dW9u3jUKWc478D5v7xoDj3Xf1nUbgL8HQ1tbm1n//PPPzXo1KOSZ/zqAn6rq\nXAD/DGCdiDwIYD2A3ao6B8Du5G0iGiXc8Ktqt6ruT17vBdAJYBaAFQC2JO+2BcAz5ZokEZXeLf3O\nLyL3AFgA4AMATaraDQz9BwHAvtaSiKpKwdf2i8hkAH8C8BNVvehdGz1s3FoAa4ubHhGVS0HP/CJS\ng6Hg/05V/5zc3CMizUm9GcDpkcaq6iZVbVfV9lJMmIhKww2/DD3FvwagU1V/Oay0E8Ca5PU1AN4s\n/fSIqFwK+bF/CYDvAzgoIh8mt20A8BKAP4rIDwAcBfC98kyxMPfff3+m8RcuXCh6rNdO84659tpp\nHmu819KyjvcuhNeGtLbf9lp9WduQ1ufmHcHttRnvvfdesz4aWn1u+FX1LwDSfsH/19JOh4gqhVf4\nEQXF8BMFxfATBcXwEwXF8BMFxfATBTVmtu5+4IEHzPpDDz1k1s+fP2/Wra2ap06dao794IMPzHpD\nQ4NZ95aXWr127xqES5cumXWv1+5tUW3dv/exT506ZdY9c+fOTa1524ZbS7gBoL3dvmD13XffNevV\ngM/8REEx/ERBMfxEQTH8REEx/ERBMfxEQTH8REGJ12st6Z2JVO7ObuL1+Q8dOmTWrS2qu7q6zLHe\nY/zyyy+b9U8//dSsW1uHnzhxwhzrrWu/fv26WW9paTHrzc3NqTXvWPQFCxaY9ZUrV5r1Z599NrW2\na9cuc2xdXZ1Z3759u1l/9NFHzXo5qWpBe+zxmZ8oKIafKCiGnygohp8oKIafKCiGnygohp8oqDB9\nfm999YEDB8y6tf/9+vXVe0BxX1+fWfeOFx/Nuru7U2t79uwxx06fPt2sP/HEE0XNqRLY5yciE8NP\nFBTDTxQUw08UFMNPFBTDTxQUw08UlLtvv4i0AtgKYAaAQQCbVPUVEXkRwA8BnEnedYOqvlWuiWa1\ndOnS3O7b2gsA8Nf7e3vvW7x161lt27bNrK9atSq1NjAwYI4VsdvVWevRFXJox3UAP1XV/SJSB6BD\nRN5JahtV1d6Jgoiqkht+Ve0G0J283isinQBmlXtiRFRet/Q7v4jcA2ABgBvnT/1YRP4qIptFZMQz\nq0RkrYjsE5F9mWZKRCVVcPhFZDKAPwH4iapeBPBrALMBzMfQTwa/GGmcqm5S1XZVtQ83I6KKKij8\nIlKDoeD/TlX/DACq2qOqA6o6COA3ABaXb5pEVGpu+GXoT6avAehU1V8Ou334tqzfBfBR6adHROVS\nyF/7lwD4PoCDIvJhctsGAKtFZD4ABdAF4EdlmWGJeEdJZ2k71dTUmGO9I7Y93vbZ1vHh3tgsH7vc\nyvm4ed8PWY5FB0ZHm7GQv/b/BcBIn0nV9vSJyMcr/IiCYviJgmL4iYJi+ImCYviJgmL4iYIKs3X3\naOZ9jaye8tGjR82xbW1tRc3phmPHjpn11tbW1FqWz4vScetuIjIx/ERBMfxEQTH8REEx/ERBMfxE\nQTH8REFVus9/BsD/DbupAcDZik3g1lTr3Kp1XgDnVqxSzu1uVbXPF09UNPzfuHORfdW6t1+1zq1a\n5wVwbsXKa278sZ8oKIafKKi8w78p5/u3VOvcqnVeAOdWrFzmluvv/ESUn7yf+YkoJ7mEX0SeFpHP\nROSIiKzPYw5pRKRLRA6KyId5HzGWHIN2WkQ+GnZbvYi8IyKHk5cjHpOW09xeFJETyWP3oYgsy2lu\nrSLyvyLSKSIfi8i/J7fn+tgZ88rlcav4j/0iMg7AIQBPATgOYC+A1ar6SUUnkkJEugC0q2ruPWER\n+RcAfQC2quq85Lb/BHBeVV9K/uOcqqr/USVzexFAX94nNycHyjQPP1kawDMA/g05PnbGvFYih8ct\nj2f+xQCOqOoXqtoPYBuAFTnMo+qp6nsAzt908woAW5LXt2Dom6fiUuZWFVS1W1X3J6/3ArhxsnSu\nj50xr1zkEf5ZAIZv/3Ic1XXktwLYJSIdIrI278mMoCk5Nv3G8emNOc/nZu7JzZV008nSVfPYFXPi\ndanlEf6RthiqppbDElV9GMB3AKxLfrylwhR0cnOljHCydFUo9sTrUssj/McBDN/YrQXAyRzmMSJV\nPZm8PA1gB6rv9OGeG4ekJi9P5zyfv6umk5tHOlkaVfDYVdOJ13mEfy+AOSLyLRG5HcAqADtzmMc3\niEht8ocYiEgtgG+j+k4f3glgTfL6GgBv5jiXf1AtJzennSyNnB+7ajvxOpeLfJJWxq8AjAOwWVV/\nXvFJjEBE/glDz/bA0CGmv89zbiLyOoDHMbTqqwfAzwD8D4A/AmgDcBTA91S14n94S5nb4xj60fXv\nJzff+B27wnN7DMAeAAcBDCY3b8DQ79e5PXbGvFYjh8eNV/gRBcUr/IiCYviJgmL4iYJi+ImCYviJ\ngmL4iYJi+ImCYviJgvp/GxdMt2RJE4UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109bf5588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x_valid[54,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_val_categorical = to_categorical(y_valid)\n",
    "y_test_categorical = to_categorical(y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 139x139; got `input_shape=(28, 28, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6b90e9721308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m base_model = applications.inception_v3.InceptionV3(include_top=False, \n\u001b[1;32m     13\u001b[0m                                 \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                 input_shape = (28, 28, 3) )\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         weights=weights)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     raise ValueError('Input size must be at least ' +\n\u001b[1;32m    298\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'; got '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 139x139; got `input_shape=(28, 28, 3)`"
     ]
    }
   ],
   "source": [
    "import keras.applications as applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "#base_model = applications.ResNet50(weights='imagenet', \n",
    "#                                   include_top=False,\n",
    "#                                  input_shape = (28, 28, 3))\n",
    "#base_model = applications.VGG19(include_top=False, \n",
    "#                                weights='imagenet', \n",
    "#                                input_shape = (28, 28, 3) )\n",
    "base_model = applications.inception_v3.InceptionV3(include_top=False, \n",
    "                                weights='imagenet', \n",
    "                                input_shape = (28, 28, 3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (None, None, 512). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0cb2f1ec013b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# x = GlobalAveragePooling2D()(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# x = MaxPool2D()(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;31m# Inferring the output shape is only relevant for Theano.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    488\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[1;32m    489\u001b[0m                              \u001b[0;34m'is not fully defined '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                              \u001b[0;34m'(got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                              \u001b[0;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                              \u001b[0;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (None, None, 512). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "#from keras.layers.core import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = MaxPool2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "from keras import optimizers\n",
    "adam = optimizers.Adam(lr=0.000001, decay=0.0000) #decay=1e-4\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Begin training\n",
      "Epoch 1/500\n",
      " 1280/54000 [..............................] - ETA: 10:04 - loss: 2.3026 - acc: 0.1039"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-67a99ceda6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0;31m#verbose=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m          )\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from fnn_helper import PlotLosses\n",
    "plot_losses = PlotLosses(plot_interval=1, evaluate_interval=None, x_val=x_valid, y_val_categorical=y_val_categorical)\n",
    "checkpointer = ModelCheckpoint(filepath='cnn-resnet.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "model.fit(x_train, \n",
    "          y_train_categorical,\n",
    "          epochs=500, batch_size=256, \n",
    "          #verbose=1, \n",
    "          validation_data=(x_valid, y_val_categorical), \n",
    "          callbacks=[plot_losses, checkpointer],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
